{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, glob\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras import layers\nfrom keras.models import Model\nfrom keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess_input\nfrom keras.applications import EfficientNetB7\nfrom keras.applications.efficientnet import preprocess_input as efficientnet_preprocess_input\nfrom keras.applications import Xception\nfrom keras.applications.xception import preprocess_input as xception_preprocess_input","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:54:25.453082Z","iopub.execute_input":"2023-11-07T08:54:25.453851Z","iopub.status.idle":"2023-11-07T08:54:41.022912Z","shell.execute_reply.started":"2023-11-07T08:54:25.453812Z","shell.execute_reply":"2023-11-07T08:54:41.021888Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <span style=\"color: blue;\">Read data and save in a dataframe</span>\n","metadata":{}},{"cell_type":"markdown","source":"Colab","metadata":{}},{"cell_type":"code","source":"!gdown 1O4YR4UBatOLnaP4gMHbmFw7UJvhhxFwq\n!gdown 1-7aMdKW4KcCKLwoUKC3XxdIwfIKkzwx6\n! unzip train_data.zip -d /content/train_data\n! unzip test_data.zip -d /content/test_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_dir = '/content/train_data/train_data'\ntest_data_dir = '/content/test_data/test_data'\nkaggle = False\npath=''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kaggle","metadata":{}},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/image-prooduct-quera/train_data/train_data'\ntest_data_dir = '/kaggle/input/image-prooduct-quera/test_data/test_data'\nkaggle = True\npath='/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2023-11-07T09:03:03.026836Z","iopub.execute_input":"2023-11-07T09:03:03.027535Z","iopub.status.idle":"2023-11-07T09:03:03.032114Z","shell.execute_reply.started":"2023-11-07T09:03:03.027502Z","shell.execute_reply":"2023-11-07T09:03:03.031191Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Save Class Names","metadata":{}},{"cell_type":"code","source":"class_names = os.listdir(train_data_dir)\nclass_names","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:54:49.944744Z","iopub.execute_input":"2023-11-07T08:54:49.945626Z","iopub.status.idle":"2023-11-07T08:54:49.962746Z","shell.execute_reply.started":"2023-11-07T08:54:49.945590Z","shell.execute_reply":"2023-11-07T08:54:49.961682Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['7', '2', '10', '5', '8', '3', '1', '4', '9', '6']"},"metadata":{}}]},{"cell_type":"markdown","source":"Read Path of all Train Images","metadata":{}},{"cell_type":"code","source":"image_dirs = list(glob.glob(train_data_dir + '/**/*.*'))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:54:52.437278Z","iopub.execute_input":"2023-11-07T08:54:52.437621Z","iopub.status.idle":"2023-11-07T08:54:53.965989Z","shell.execute_reply.started":"2023-11-07T08:54:52.437595Z","shell.execute_reply":"2023-11-07T08:54:53.964689Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(image_dirs)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:36:35.024642Z","iopub.execute_input":"2023-11-07T07:36:35.025374Z","iopub.status.idle":"2023-11-07T07:36:35.033784Z","shell.execute_reply.started":"2023-11-07T07:36:35.025331Z","shell.execute_reply":"2023-11-07T07:36:35.032106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read Label of Train Images","metadata":{}},{"cell_type":"code","source":"labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], image_dirs))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:54:58.787447Z","iopub.execute_input":"2023-11-07T08:54:58.787800Z","iopub.status.idle":"2023-11-07T08:54:58.828765Z","shell.execute_reply.started":"2023-11-07T08:54:58.787770Z","shell.execute_reply":"2023-11-07T08:54:58.827872Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"len(labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:36:35.091158Z","iopub.execute_input":"2023-11-07T07:36:35.092263Z","iopub.status.idle":"2023-11-07T07:36:35.100746Z","shell.execute_reply.started":"2023-11-07T07:36:35.092220Z","shell.execute_reply":"2023-11-07T07:36:35.099261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create DataFrame of Paths and Labels","metadata":{}},{"cell_type":"code","source":"data = pd.DataFrame({'image_dir':image_dirs, 'label': labels})\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:55:01.435544Z","iopub.execute_input":"2023-11-07T08:55:01.436476Z","iopub.status.idle":"2023-11-07T08:55:01.465274Z","shell.execute_reply.started":"2023-11-07T08:55:01.436432Z","shell.execute_reply":"2023-11-07T08:55:01.464076Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                           image_dir label\n0  /kaggle/input/image-prooduct-quera/train_data/...     7\n1  /kaggle/input/image-prooduct-quera/train_data/...     7\n2  /kaggle/input/image-prooduct-quera/train_data/...     7\n3  /kaggle/input/image-prooduct-quera/train_data/...     7\n4  /kaggle/input/image-prooduct-quera/train_data/...     7","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_dir</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/image-prooduct-quera/train_data/...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/image-prooduct-quera/train_data/...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/image-prooduct-quera/train_data/...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/image-prooduct-quera/train_data/...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/image-prooduct-quera/train_data/...</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Check Number of Samples in each Class","metadata":{}},{"cell_type":"code","source":"counts = data['label'].value_counts()\nsns.barplot(x=counts.index, y=counts)\nplt.xlabel('Classes')\nplt.ylabel('Count')\n# plt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:04:10.767014Z","iopub.execute_input":"2023-11-05T11:04:10.767491Z","iopub.status.idle":"2023-11-05T11:04:11.037784Z","shell.execute_reply.started":"2023-11-05T11:04:10.767465Z","shell.execute_reply":"2023-11-05T11:04:11.036839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot some images in each class","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(20,25))\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(data['image_dir'][i * 500]))\n    ax.set_title('Class : ' + data['label'][i * 500], fontsize=17)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:04:11.039500Z","iopub.execute_input":"2023-11-05T11:04:11.039815Z","iopub.status.idle":"2023-11-05T11:04:16.103049Z","shell.execute_reply.started":"2023-11-05T11:04:11.039776Z","shell.execute_reply":"2023-11-05T11:04:16.101518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color: blue;\">Define Functions</span>","metadata":{}},{"cell_type":"markdown","source":"## Function for generators of train , validation and test","metadata":{}},{"cell_type":"code","source":"def create_generators(data, \n                      test_size, \n                      preprocessing_function,\n                      batch_size = 32,\n                      image_size = (224, 224)\n                     ):\n    \n    # Split Data to Tain and Validation\n    train, validation = train_test_split(data, test_size=test_size, random_state=42)\n    train = train.reset_index(drop=True)\n    validation = validation.reset_index(drop=True)\n    \n    # Create Data Generators\n    train_data_generator = ImageDataGenerator(\n    preprocessing_function=preprocessing_function,\n    rotation_range=15, \n#     width_shift_range=0.2,  \n#     height_shift_range=0.2, \n    brightness_range=[0.8,1.2],\n    shear_range=0.2,  \n    zoom_range=0.2, \n    horizontal_flip=True,\n#     vertical_flip=True,\n    fill_mode='nearest' \n    )\n    \n    test_data_generator = ImageDataGenerator(\n            preprocessing_function=preprocessing_function\n        )\n\n    train_generator = train_data_generator.flow_from_dataframe(\n        dataframe= train,\n        x_col='image_dir',\n        y_col='label',\n        target_size=image_size,\n        batch_size=batch_size,\n        class_mode='categorical', \n        shuffle=True,\n        seed=42\n    )\n    validation_generator = test_data_generator.flow_from_dataframe(\n        dataframe= validation,\n        x_col='image_dir',\n        y_col='label',\n        target_size=image_size,\n        batch_size=batch_size,\n        class_mode='categorical', \n        shuffle=False\n    )\n\n    # test_generator = test_data_generator\n    \n    return train_generator, validation_generator, test_data_generator","metadata":{"execution":{"iopub.status.busy":"2023-11-07T11:46:06.191217Z","iopub.execute_input":"2023-11-07T11:46:06.191617Z","iopub.status.idle":"2023-11-07T11:46:06.203012Z","shell.execute_reply.started":"2023-11-07T11:46:06.191585Z","shell.execute_reply":"2023-11-07T11:46:06.201894Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def create_generators2(train_data_dir,\n                       test_data_dir,\n                      preprocessing_function,\n                      batch_size = 32,\n                      image_size = (224, 224),\n                      validation_split=0.3\n                     ):\n    # Create Data Generators\n    train_data_generator = ImageDataGenerator(\n        preprocessing_function=preprocessing_function,\n        validation_split=validation_split \n    )\n\n    test_data_generator = ImageDataGenerator(\n        preprocessing_function=preprocessing_function,\n        validation_split=validation_split  \n    )\n\n    \n    train_generator = train_data_generator.flow_from_directory(\n        directory=train_data_dir,\n        target_size=image_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True,\n        subset='training', \n        seed=42\n    )\n    \n    validation_generator = test_data_generator.flow_from_directory(\n        directory=train_data_dir,\n        target_size=image_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False,\n        subset='validation',  \n        seed=42\n    )\n\n    return train_generator, validation_generator, test_data_generator","metadata":{"execution":{"iopub.status.busy":"2023-11-07T13:14:32.828624Z","iopub.execute_input":"2023-11-07T13:14:32.829476Z","iopub.status.idle":"2023-11-07T13:14:32.838971Z","shell.execute_reply.started":"2023-11-07T13:14:32.829432Z","shell.execute_reply":"2023-11-07T13:14:32.837839Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def augment_batch(x_batch, y_batch, data_gen: ImageDataGenerator):\n    augmented_images = []\n    augmented_labels = []\n    \n    for x, y in zip(x_batch, y_batch):\n        \n        augmented_images.append(x)\n        augmented_labels.append(y)\n        \n        x_aug = data_gen.random_transform(x)\n        augmented_images.append(x_aug)\n        augmented_labels.append(y)\n    \n    augmented_images = np.array(augmented_images)\n    augmented_labels = np.array(augmented_labels)\n    \n    return augmented_images, augmented_labels","metadata":{"execution":{"iopub.status.busy":"2023-11-07T13:10:43.760038Z","iopub.execute_input":"2023-11-07T13:10:43.761203Z","iopub.status.idle":"2023-11-07T13:10:43.767247Z","shell.execute_reply.started":"2023-11-07T13:10:43.761167Z","shell.execute_reply":"2023-11-07T13:10:43.766400Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def custom_generator(generator, data_gen):\n    for x_batch, y_batch in generator:\n        x_batch_aug, y_batch_aug = augment_batch(x_batch, y_batch, data_gen)\n        yield x_batch_aug, y_batch_aug","metadata":{"execution":{"iopub.status.busy":"2023-11-07T13:12:32.246173Z","iopub.execute_input":"2023-11-07T13:12:32.247010Z","iopub.status.idle":"2023-11-07T13:12:32.251899Z","shell.execute_reply.started":"2023-11-07T13:12:32.246978Z","shell.execute_reply":"2023-11-07T13:12:32.250982Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Functions make pretrained model as base model ","metadata":{}},{"cell_type":"code","source":"def make_base_model(model=ResNet50,\n                    image_size=(224,224),\n                    num_classes=10,\n                    num_trainable_layeres=0,\n                    kaggle=False,\n                    weights_path=None,\n                   ):\n    \n    # base_model\n    if kaggle:\n        # Kaggle\n        base_model = model(\n        input_shape=(image_size[0], image_size[1], 3),\n        classes=num_classes,\n        include_top=False, \n        weights=None,\n        pooling=None #'avg'\n        )\n        base_model.load_weights(weights_path)\n    else:\n        # Colab\n        base_model = model(\n        input_shape=(image_size[0], image_size[1], 3),\n        classes=num_classes,\n        include_top=False, \n        weights='imagenet',\n        pooling=None #'avg'\n        )\n    for layer in base_model.layers:\n        layer.trainable = False\n    if num_trainable_layeres > 0:\n        for layer in base_model.layers[-num_trainable_layeres : ]:\n            if not isinstance(layer, layers.BatchNormalization):\n                layer.trainable = True    \n    \n    return base_model","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:55:18.232914Z","iopub.execute_input":"2023-11-07T08:55:18.233281Z","iopub.status.idle":"2023-11-07T08:55:18.241813Z","shell.execute_reply.started":"2023-11-07T08:55:18.233250Z","shell.execute_reply":"2023-11-07T08:55:18.240782Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Function for add our layeres to base model","metadata":{}},{"cell_type":"code","source":"def try_model(base_model, \n              n_added_layers=2, \n              filters=[128,128], \n              activations=['relu', 'relu'], \n              augmentation_layer=False,\n              num_classes=10,\n              optimizer=Adam(learning_rate=1e-3),\n              metrics=['accuracy']):\n    if augmentation_layer:\n        data_augmentation = keras.Sequential(\n        [\n        layers.RandomRotation(0.1),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomFlip(),\n        layers.RandomContrast(factor=0.1),\n        ]\n        )\n        inputs = base_model.input\n        x = data_augmentation(inputs)\n#         scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n#         x = scale_layer(x)\n        x = base_model(x, training=False)\n        x = GlobalAveragePooling2D()(x)\n        x = layers.BatchNormalization()(x)\n        x = keras.layers.Dropout(0.2)(x) \n        \n    else:\n        x = base_model.output\n        x = GlobalAveragePooling2D()(x)\n        x = layers.BatchNormalization()(x)\n        x = keras.layers.Dropout(0.2)(x) \n        \n    for i in range(n_added_layers):\n        x = Dense(filters[i], activation='relu')(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    trainable_params = np.sum([K.count_params(p) for p in model.trainable_weights])\n    non_trainable_params = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n    total_params = trainable_params + non_trainable_params\n    \n    print(f\"Total params: {total_params:,}\")\n    print(f\"Trainable params: {trainable_params:,}\")\n    print(f\"Non-trainable params: {non_trainable_params:,}\")\n    \n    model.compile(loss='categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=metrics)\n#     model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-07T13:16:56.655590Z","iopub.execute_input":"2023-11-07T13:16:56.656231Z","iopub.status.idle":"2023-11-07T13:16:56.667851Z","shell.execute_reply.started":"2023-11-07T13:16:56.656197Z","shell.execute_reply":"2023-11-07T13:16:56.666969Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Functions for evaluation metrics ","metadata":{}},{"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n\ndef f1_micro(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    actual_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    \n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (actual_positives + K.epsilon())\n    \n    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n    \n    return f1","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:56:38.349305Z","iopub.execute_input":"2023-11-07T08:56:38.349656Z","iopub.status.idle":"2023-11-07T08:56:38.359740Z","shell.execute_reply.started":"2023-11-07T08:56:38.349628Z","shell.execute_reply":"2023-11-07T08:56:38.358614Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Functions for save and load models","metadata":{}},{"cell_type":"code","source":"def save_model(model, filename, path=''):\n    filename_json = os.path.join(path, filename + '.json')\n    filename_h5 = os.path.join(path, filename + '.h5')\n\n    # serialize model to JSON\n    model_json = model.to_json()\n    with open(filename_json, \"w\") as json_file:\n        json_file.write(model_json)\n\n    # serialize weights to HDF5\n    model.save_weights(filename_h5)\n    print(\"Saved model to \", filename_h5 )\n    \ndef load_model(model, filename, path=''):\n    filename_json = os.path.join(path, filename + '.json')\n    filename_h5 = os.path.join(path, filename + '.h5')\n    \n    # load json and create model\n    json_file = open(filename_json , 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    loaded_model = keras.models.model_from_json(loaded_model_json)\n\n    # load weights into new model\n    loaded_model.load_weights(filename_h5)\n    return loaded_model","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:56:42.425339Z","iopub.execute_input":"2023-11-07T08:56:42.425691Z","iopub.status.idle":"2023-11-07T08:56:42.433475Z","shell.execute_reply.started":"2023-11-07T08:56:42.425663Z","shell.execute_reply":"2023-11-07T08:56:42.432501Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_data_generator = ImageDataGenerator(\n        rotation_range=20,\n        brightness_range=[0.8,1.2],\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )","metadata":{"execution":{"iopub.status.busy":"2023-11-07T13:13:24.957246Z","iopub.execute_input":"2023-11-07T13:13:24.957618Z","iopub.status.idle":"2023-11-07T13:13:24.962808Z","shell.execute_reply.started":"2023-11-07T13:13:24.957590Z","shell.execute_reply":"2023-11-07T13:13:24.961828Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color: blue;\">Try Models</span>","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"color: green;\">ResNet 50</span>","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nimage_size = (224, 224)\n\ntrain_generator, validation_generator, test_data_generator = create_generators(data, \n                      test_size= 0.3, \n                      preprocessing_function= resnet50_preprocess_input,\n                      batch_size = batch_size,\n                      image_size = image_size\n                     )","metadata":{"execution":{"iopub.status.busy":"2023-11-06T10:37:08.577769Z","iopub.execute_input":"2023-11-06T10:37:08.578192Z","iopub.status.idle":"2023-11-06T10:37:23.905021Z","shell.execute_reply.started":"2023-11-06T10:37:08.578135Z","shell.execute_reply":"2023-11-06T10:37:23.904084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet 50 | train 0 layers ","metadata":{}},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=0,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 0,\n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-3),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n                                               min_delta=0,\n                                               patience=5,\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_0_layers', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T13:04:02.649957Z","iopub.execute_input":"2023-11-06T13:04:02.650857Z","iopub.status.idle":"2023-11-06T13:04:06.037740Z","shell.execute_reply.started":"2023-11-06T13:04:02.650820Z","shell.execute_reply":"2023-11-06T13:04:06.036279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet 50 | train 0 layers | add 2 dense layer with 128 filters","metadata":{}},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=0,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [128,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-3),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n                                               min_delta=0,\n                                               patience=5,\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_0_add_2_layers', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:36:45.829401Z","iopub.execute_input":"2023-11-05T11:36:45.829775Z","iopub.status.idle":"2023-11-05T11:55:46.007454Z","shell.execute_reply.started":"2023-11-05T11:36:45.829745Z","shell.execute_reply":"2023-11-05T11:55:46.006457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet 50 | train 5 last layers | add 2 dense layers both with 128 filters","metadata":{}},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=5,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [128,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-3),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_5_add_2_layers_128_128', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T14:09:34.199279Z","iopub.execute_input":"2023-11-05T14:09:34.199676Z","iopub.status.idle":"2023-11-05T14:14:07.872114Z","shell.execute_reply.started":"2023-11-05T14:09:34.199645Z","shell.execute_reply":"2023-11-05T14:14:07.870426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet 50 | train 10 last layers | add 2 dense layer with 256 and 128 filters","metadata":{}},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=10,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-3),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_10_add_2_layers_256_128', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T14:14:23.393297Z","iopub.execute_input":"2023-11-05T14:14:23.394015Z","iopub.status.idle":"2023-11-05T15:26:50.417643Z","shell.execute_reply.started":"2023-11-05T14:14:23.393979Z","shell.execute_reply":"2023-11-05T15:26:50.416189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet 50 | train 15 last layers | add 2 dense layer with 256 and 128 filters","metadata":{}},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=15,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-3),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_15_add_2_layers_256_128', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T15:36:32.059485Z","iopub.execute_input":"2023-11-05T15:36:32.059848Z","iopub.status.idle":"2023-11-05T16:47:03.898264Z","shell.execute_reply.started":"2023-11-05T15:36:32.059822Z","shell.execute_reply":"2023-11-05T16:47:03.897194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet 50 | train 20 last layers | add 2 dense layer with 256 and 128 filters | lr : 1e-4","metadata":{}},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=20,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-4),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_20_add_2_layers_256_128_lr-4', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:47:03.900848Z","iopub.execute_input":"2023-11-05T16:47:03.901646Z","iopub.status.idle":"2023-11-05T17:53:47.342288Z","shell.execute_reply.started":"2023-11-05T16:47:03.901610Z","shell.execute_reply":"2023-11-05T17:53:47.341235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet 50 | train 25 last layers | add 2 dense layer with 256 and 128 filters | lr : 1e-4","metadata":{}},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=25,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-4),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_25_add_2_layers_256_128_lr-4', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T10:37:56.540265Z","iopub.execute_input":"2023-11-06T10:37:56.540631Z","iopub.status.idle":"2023-11-06T11:16:56.488125Z","shell.execute_reply.started":"2023-11-06T10:37:56.540602Z","shell.execute_reply":"2023-11-06T11:16:56.486977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=45,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-4),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_45_add_2_layers_256_128_lr-4', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T11:26:46.588886Z","iopub.execute_input":"2023-11-06T11:26:46.589319Z","iopub.status.idle":"2023-11-06T11:50:54.037403Z","shell.execute_reply.started":"2023-11-06T11:26:46.589284Z","shell.execute_reply":"2023-11-06T11:50:54.036456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_weights_path = '/kaggle/input/resnet50-weights-notop/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = make_base_model(model=ResNet50,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=20,\n                    kaggle=kaggle,\n                    weights_path=resnet50_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-4),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // batch_size,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='resnet50_train_20_add_2_layers_256_128_lr-4', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T13:18:06.721179Z","iopub.execute_input":"2023-11-06T13:18:06.721517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color: green;\">EfficientNet</span>","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nimage_size = (224, 224)\ntrain_generator, validation_generator, test_data_generator = create_generators(data, \n                      test_size= 0.3, \n                      preprocessing_function= efficientnet_preprocess_input,\n                      batch_size = batch_size,\n                      image_size = image_size\n                     )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efficientnet_weights_path = '/kaggle/input/efficientnetb7-weights-notop/efficientnetb7_notop.h5'\nbase_model = make_base_model(model=EfficientNetB7,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=20,\n                    kaggle=kaggle,\n                    weights_path=efficientnet_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-4),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // batch_size,\n    epochs=100,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='efficientnet_train_20_add_2_layers_256_128_lr-4', \n           path=path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color: green;\">Xception</span>","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nimage_size = (299, 299)\n\ntrain_generator, validation_generator, test_data_generator = create_generators(data, \n                      test_size= 0.3, \n                      preprocessing_function= xception_preprocess_input,\n                      batch_size = batch_size,\n                      image_size = image_size\n                     )","metadata":{"execution":{"iopub.status.busy":"2023-11-07T11:46:57.102892Z","iopub.execute_input":"2023-11-07T11:46:57.103293Z","iopub.status.idle":"2023-11-07T11:47:15.034772Z","shell.execute_reply.started":"2023-11-07T11:46:57.103261Z","shell.execute_reply":"2023-11-07T11:47:15.033955Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Found 6993 validated image filenames belonging to 10 classes.\nFound 2997 validated image filenames belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_generator, validation_generator, test_data_generator = create_generators2(train_data_dir,\n                      test_data_dir,\n                      validation_split=0.3,\n                      preprocessing_function= xception_preprocess_input,\n                      batch_size = batch_size,\n                      image_size = image_size\n                      \n                     )","metadata":{"execution":{"iopub.status.busy":"2023-11-07T13:15:26.550791Z","iopub.execute_input":"2023-11-07T13:15:26.551511Z","iopub.status.idle":"2023-11-07T13:15:32.844238Z","shell.execute_reply.started":"2023-11-07T13:15:26.551477Z","shell.execute_reply":"2023-11-07T13:15:32.843495Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Found 6994 images belonging to 10 classes.\nFound 2996 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"xception_weights_path = '/kaggle/input/xception-weights-notop/xception-weights-notop.h5'\nbase_model = make_base_model(model=Xception,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=20,\n                    kaggle=kaggle,\n                    weights_path=xception_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-4),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    custom_generator(train_generator, train_data_generator),\n    steps_per_epoch=train_generator.samples // batch_size,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // batch_size,\n    epochs=50,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='xception_train_20_add_2_layers_256_128_lr-4', \n           path=path)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T13:21:13.793861Z","iopub.execute_input":"2023-11-07T13:21:13.794229Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Total params: 21,428,402\nTrainable params: 7,875,026\nNon-trainable params: 13,553,376\nEpoch 1/50\n 93/218 [===========>..................] - ETA: 2:04 - loss: 1.8111 - accuracy: 0.3967 - f1_micro: 0.2819","output_type":"stream"}]},{"cell_type":"code","source":"xception_weights_path = '/kaggle/input/xception-weights-notop/xception-weights-notop.h5'\nbase_model = make_base_model(model=Xception,\n                    image_size=image_size,\n                    num_classes=len(class_names),\n                    num_trainable_layeres=20,\n                    kaggle=kaggle,\n                    weights_path=xception_weights_path,\n                   )\n\nmodel = try_model(base_model, \n              n_added_layers= 2, \n              filters= [256,128], \n              activations= ['relu', 'relu'], \n              num_classes= len(class_names),\n              optimizer= Adam(learning_rate=1e-4),\n              metrics= ['accuracy', f1_micro])\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_f1_micro',\n                                               min_delta=0,\n                                               patience=5,\n                                               mode='max',\n                                               restore_best_weights=True)\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // batch_size,\n    epochs=50,\n    callbacks=[early_stopping]\n)\n\n# save model\nsave_model(model, \n           filename='xception_train_20_add_2_layers_256_128_lr-4', \n           path=path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}